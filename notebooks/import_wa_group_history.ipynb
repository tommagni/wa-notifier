{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:06.382231Z",
     "start_time": "2025-03-04T17:05:06.379026Z"
    }
   },
   "outputs": [],
   "source": [
    "my_number = \"972545380874\"\n",
    "chat_file = \"founders_chat.txt\"\n",
    "group_name = \"GenAI Founders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:06.960705Z",
     "start_time": "2025-03-04T17:05:06.437669Z"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from whatstk import WhatsAppChat\n",
    "\n",
    "from utils.importing_wa import (\n",
    "    merge_contact_dfs,\n",
    "    filter_messages,\n",
    "    match_and_rename_users,\n",
    "    split_chats,\n",
    ")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "def parse_chat(filename: str, group_name: str):\n",
    "    wa_chat = WhatsAppChat.from_source(filepath=filename)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "\n",
    "        contacts_df = merge_contact_dfs(\n",
    "            pd.read_csv(\"whatsmeow_contacts.csv\"),\n",
    "            pd.read_csv(\"whatsmeow_contacts2.csv\"),\n",
    "            pd.read_csv(\"whatsmeow_contacts3.csv\"),\n",
    "            pd.read_csv(\"whatsmeow_contacts4.csv\"),\n",
    "            pd.read_csv(\"whatsmeow_contacts_202502090741.csv\"),\n",
    "        )\n",
    "        wa_chat = match_and_rename_users(wa_chat, contacts_df)\n",
    "\n",
    "    chat_df = wa_chat.df\n",
    "    chat_df[\"username\"] = chat_df[\"username\"].apply(\n",
    "        lambda n: n.replace(\"(\", \"\")\n",
    "        .replace(\")\", \"\")\n",
    "        .replace(\" \", \"\")\n",
    "        .replace(\"-\", \"\")\n",
    "        .replace(\"‐\", \"\")[1:]\n",
    "        if n.startswith(\"+\")\n",
    "        else n\n",
    "    )\n",
    "\n",
    "    chat_df[\"group\"] = group_name\n",
    "    chat_df[\"id\"] = [f\"imported_{uuid.uuid4()}\" for _ in range(len(chat_df))]\n",
    "    chat_df = filter_messages(chat_df)\n",
    "\n",
    "    # export as filename but with .csv ext\n",
    "    chat_df.to_csv(Path(filename).with_suffix(\".csv\"))\n",
    "    return chat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:09.704017Z",
     "start_time": "2025-03-04T17:05:06.964755Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_df = parse_chat(chat_file, group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:10.184516Z",
     "start_time": "2025-03-04T17:05:09.710887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/almogbaku/projects/kelet/wa_llm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "from sqlmodel.ext.asyncio.session import AsyncSession\n",
    "from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker\n",
    "\n",
    "from sqlmodel import select\n",
    "from config import Settings\n",
    "from models.group import Group\n",
    "from voyageai.client_async import AsyncClient\n",
    "\n",
    "settings = Settings()  # pyright: ignore [reportCallIssue]\n",
    "\n",
    "engine = create_async_engine(\n",
    "    settings.db_uri,\n",
    "    pool_size=50,\n",
    "    max_overflow=400,\n",
    "    pool_timeout=90,\n",
    "    pool_pre_ping=True,\n",
    "    pool_recycle=600,\n",
    "    future=True,\n",
    "    connect_args={\"timeout\": 60},\n",
    ")\n",
    "async_session = async_sessionmaker(engine, expire_on_commit=False, class_=AsyncSession)\n",
    "\n",
    "embedding_client = AsyncClient(\n",
    "    api_key=settings.voyage_api_key, max_retries=settings.voyage_max_retries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:10.204483Z",
     "start_time": "2025-03-04T17:05:10.192653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total conversations: 6\n"
     ]
    }
   ],
   "source": [
    "# Identify conversations\n",
    "conversation_dfs = split_chats(chat_df, \"date\")\n",
    "print(f\"total conversations: {len(conversation_dfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:10.332031Z",
     "start_time": "2025-03-04T17:05:10.218568Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from load_new_kbtopics import get_conversation_topics, load_topics\n",
    "from models import Message\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    wait_random_exponential,\n",
    "    stop_after_attempt,\n",
    "    before_sleep_log,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=10, max=90),\n",
    "    stop=stop_after_attempt(6),\n",
    "    before_sleep=before_sleep_log(logger, logging.DEBUG),\n",
    "    reraise=True,\n",
    ")\n",
    "async def _process_conversation(df, group) -> Dict:\n",
    "    messages = [\n",
    "        Message(\n",
    "            message_id=f\"na-{row['date']}\",\n",
    "            timestamp=row[\"date\"],\n",
    "            chat_jid=group.group_jid,\n",
    "            text=row[\"message\"],\n",
    "            sender_jid=row[\"username\"],\n",
    "            group_jid=group.group_jid,\n",
    "        )\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    if len(messages) == 0:\n",
    "        return\n",
    "    topics = await get_conversation_topics(messages, my_number)\n",
    "    # print(f\"different conversations: {len(topics)}; topics: {\",\".join([t.subject for t in topics])}\")\n",
    "    async with async_session() as session:\n",
    "        group = await session.merge(group)\n",
    "        await load_topics(\n",
    "            session,\n",
    "            group,\n",
    "            embedding_client,\n",
    "            topics,\n",
    "            df[\"date\"].min().to_pydatetime(),\n",
    "        )\n",
    "        await session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:16.618844Z",
     "start_time": "2025-03-04T17:05:10.356068Z"
    }
   },
   "outputs": [],
   "source": [
    "async with async_session() as session:\n",
    "    res = await session.exec(\n",
    "        select(Group).where(Group.group_name == chat_df.iloc[0][\"group\"])\n",
    "    )\n",
    "    group = res.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:48.510904Z",
     "start_time": "2025-03-04T17:05:16.625527Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Conversations:   0%|          | 0/6 [00:00<?, ?it/s]/Users/almogbaku/projects/kelet/wa_llm/src/daily_ingest/daily_ingest.py:60: LogfireNotConfiguredWarning:\n",
      "\n",
      "No logs or spans will be created until `logfire.configure()` has been called. Set the environment variable LOGFIRE_IGNORE_NO_CONFIG=1 or add ignore_no_config=true in pyproject.toml to suppress this warning.\n",
      "\n",
      "Processing Conversations: 100%|██████████| 6/6 [00:31<00:00,  5.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "# Maximum number of concurrent tasks\n",
    "MAX_CONCURRENT_TASKS = 30\n",
    "\n",
    "# File to store processed conversation indices\n",
    "processed_file = f\"{group.group_jid}_processed.json\"\n",
    "\n",
    "# Load processed conversation indices\n",
    "if Path(processed_file).exists():\n",
    "    with open(processed_file, \"r\") as f:\n",
    "        processed_indices = set(json.load(f))\n",
    "else:\n",
    "    processed_indices = set()\n",
    "\n",
    "# Calculate total items\n",
    "total_conversations = len(conversation_dfs)\n",
    "\n",
    "# Semaphore to limit concurrency\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)\n",
    "\n",
    "# Lock for updating the processed set\n",
    "processed_lock = asyncio.Lock()\n",
    "\n",
    "\n",
    "# Process conversation with progress tracking\n",
    "async def process_conversation(df, group, idx):\n",
    "    async with semaphore:\n",
    "        await _process_conversation(df, group)\n",
    "        # Update the processed set\n",
    "        async with processed_lock:\n",
    "            processed_indices.add(idx)\n",
    "            with open(processed_file, \"w\") as f:\n",
    "                json.dump(sorted(processed_indices), f, indent=2)\n",
    "\n",
    "\n",
    "# Filter out already processed conversations\n",
    "tasks = [\n",
    "    process_conversation(df, group, idx)\n",
    "    for idx, df in enumerate(conversation_dfs)\n",
    "    if idx not in processed_indices\n",
    "]\n",
    "\n",
    "# Create progress bar\n",
    "with tqdm_asyncio(total=len(tasks), desc=\"Processing Conversations\") as pbar:\n",
    "    for f in asyncio.as_completed(tasks):\n",
    "        await f\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T17:05:48.527221Z",
     "start_time": "2025-03-04T17:05:48.525352Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
